# Default values for looker.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: honestica/looker
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# This will be appended to the current 'env:' key. You can use any of the kubernetes env
# syntax here
extraEnvs:
  # --shared-storage-dir=/data/: share storage for a standalone instance
  # /home/looker/looker-db.yml: specify where db credentials are stored
 - name: LOOKEREXTRAARGS
   value: --shared-storage-dir=/data/ #-d /home/looker/looker-db.yml
#  - name: JAVAARGS
#    value:
#  - name: JAVAJVMARGS
#    value: -XX:+UseG1GC -XX:MaxGCPauseMillis=2000 -XX:MinRAMPercentage=50 -XX:MaxRAMPercentage=80
#  - name: LOOKERARGS
#    value: --no-daemonize --log-format=json --no-log-to-file
#  - name: PROTOCOL
#    value: https

# by default a in-memory database is created

# -d /home/looker/looker-db.yml must be added in LOOKEREXTRAARGS
# databaseConfigFile:|-
  # dialect: mysql
  # host: YOUR_HOSTNAME
  # username: YOUR_USERNAME
  # password: YOUR_PASSWORD
  # database: YOUR_DBNAME
  # port: YOUR_PORT

# -d /home/looker/looker-db.yml must be added in LOOKEREXTRAARGS
# You can provide it as an already existing secret with the key looker-db.yml: contain the whole file
# databaseConfigSecretName: looker-db-secret

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# If not ennabled /data will be stored in memory and lost at each restart
persistence:
  enabled: false
  accessMode: ReadWriteOnce
  ## If defined, storageClass: <storageClass>
  ## If set to "-", storageClass: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClass spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # existingClaim:
  # annotations:
  #  "helm.sh/resource-policy": keep
  # storageClass: "-"
  storageSize: 10Gi
  # If PersistentDisk already exists you can create a PV for it by including the 2 following keypairs.
  # pdName: teleport-data-disk
  # fsType: ext4

podAnnotations: {}

podSecurityContext:
  fsGroup: 2000

securityContext:
  capabilities:
    drop:
    - ALL
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 2000

service:
  type: ClusterIP

ingress:
  enabled: false
  annotations: {}
    # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

ingressApi:
  enabled: false
  annotations: {}
    # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example-api.local
      paths: []
  tls: []
  #  - secretName: chart-example-api-tls
  #    hosts:
  #      - chart-example-api.local


ingressHealthcheck:
  enabled: false
  annotations: {}
    # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example-healthcheck.local
  tls: []
  #  - secretName: chart-example-api-tls
  #    hosts:
  #      - chart-example-api.local


networkPolicies:
  enabled: false
  tooling:
    enabled: false
  dbRanges:
    mysql: []
    postgres: []

backup:
  enabled: false

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
